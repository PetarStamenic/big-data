{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "354e8971-ff02-4ef4-922a-6c5c21dc0bcc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Sta rade botovi po nasem sajtu i koliko ih je\n",
    "\n",
    "## Definisemo nasu semu jer CSV nije imao header\n",
    "\n",
    "nakon detaljnijeg prolazenja kroz data set video sam da se pojavljuje action 142 na 2 mesta iz nekog razloga i on mora da se excluduje iz naseg data seta jer sajtovi nemaju akciju 142 vec samo edit , new , categorize and log\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c35344a6-5ff7-4920-ba23-65e334a904fe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+--------------------+----------------+-----+\n|        id|    action|               title|             comment|            user|  bot|\n+----------+----------+--------------------+--------------------+----------------+-----+\n|2133549229|      edit|           Q36267081|/* wbsetreference...|          Cewbot| true|\n|2133549228|      edit|           Q64923313|/* wbcreateclaim-...|         Mitsjol|false|\n|1734135754|categorize|Category:Players ...|[[:Willie Adams (...|Dominus Moravian|false|\n|1734135755|categorize|Category:WikiProj...|[[:Talk:Pfandbrie...|  Qwerfjkl (bot)| true|\n|2133549230|      edit|           Q61043507|/* wbsetlabel-add...|         StultuS|false|\n|  76240560|      edit|   טיוטה:מבצר מסילחה|/* קישורים חיצוני...|  Danny Gershoni|false|\n|2133549232|      edit|          Q116332994|/* wbeditentity-u...|     Dcirovicbot| true|\n|1734135756|      edit|Talk:New York Sta...|[[User:Cewbot/log...|          Cewbot| true|\n|2133549231|      edit|          Q113290759|/* wbsetqualifier...|           Kpjas|false|\n| 300538557|      edit|          تعليم بديل|/* من القرن الثام...|       RASHEEDYE|false|\n|1734135757|      edit|     Hank the Cowdog| /* List of books */|         Delcity|false|\n|1734135759|categorize|Category:WikiProj...|[[:Talk:New York ...|          Cewbot| true|\n|      null|      edit|File:Threshold-4 ...|[[User:Flickrevie...|  FlickreviewR 2| true|\n|1734135758|      edit|William H. Natche...|     fixed bare urls|        Villaida|false|\n|  76240561|      edit|         אהרן אמינוף| /* קריירה משפטית */|          דוד שי|false|\n|      null|       log|File:World of Mon...|Transferred from ...|    Yinweiaiqing|false|\n|1734135760|      edit|          Talk:Vowpa|Implementing [[WP...|  Qwerfjkl (bot)| true|\n|2133549233|      edit|           Q27031029|/* wbsetdescripti...|      Florentyna|false|\n|      null|      edit|File:Casa de la c...|/* wbeditentity-u...|   SchlurcherBot| true|\n|2133549235|      edit|           Q36267081|/* wbcreateclaim-...|          Cewbot| true|\n+----------+----------+--------------------+--------------------+----------------+-----+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, BooleanType\n",
    "\n",
    "# Define the schema\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"action\", StringType(), True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"comment\", StringType(), True),\n",
    "    StructField(\"user\", StringType(), True),\n",
    "    StructField(\"bot\", BooleanType(), True)\n",
    "    # Add as many columns as you have in your CSV\n",
    "])\n",
    "\n",
    "# Read the CSV file\n",
    "df = spark.read.format(\"csv\").option(\"header\", \"true\").schema(schema).load(\"dbfs:/FileStore/shared_uploads/pstamenic7721rn@raf.rs/output0-1.csv\")\n",
    "\n",
    "df = df.filter(df.action != \"142\")\n",
    "# Show the DataFrame\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4c27a29-be65-4a5a-86ac-5f1894d3edae",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Veoma nam je bitno da vidimo koliko usera koristi koju funkcionalnost na nasem sajtu kao i koji je odnos botova prema pravim userima pri tim funkcionalnostima\n",
    "\n",
    "Ovde mozemo videti sta se desava ispod haube, koliko je aktivnih korisnika na nasem sajtu a koliko je botova\n",
    "\n",
    "Ukoliko u nekom vecem vremenskom periodu primetimo da se broj botova za logovanje smanjuje to moze predstavljati da je jedan od nasih botova prestao sa radom dok ukoliko porast u broju botova za logovanje bez da smo mi dodavalai dodatne botove to moze znaciti da neko prisluskuje desavanja na nasem sajtu.\n",
    "\n",
    "Takodje mozemo videti i koliko je contenta na nasem sajtu napisano od strane botova u poredjenju sa ljudima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97970820-acbb-475c-8d62-b2a407bae95c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+----------------------+\n|    action|distinct_bot_users|distinct_non_bot_users|\n+----------+------------------+----------------------+\n|       new|                12|                   264|\n|       log|                 7|                   272|\n|      edit|                82|                  2509|\n|categorize|                37|                   684|\n+----------+------------------+----------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "# Assuming 'df' is your Spark DataFrame\n",
    "\n",
    "# Count distinct bot users aggregated by action\n",
    "bot_user_count = df.filter(df[\"bot\"] == True).groupBy(\"action\").agg(countDistinct(\"user\").alias(\"distinct_bot_users\"))\n",
    "\n",
    "# Count distinct non-bot users aggregated by action\n",
    "non_bot_user_count = df.filter(df[\"bot\"] == False).groupBy(\"action\").agg(countDistinct(\"user\").alias(\"distinct_non_bot_users\"))\n",
    "\n",
    "# Join the two results on the action column\n",
    "action_user_counts = bot_user_count.join(non_bot_user_count, \"action\")\n",
    "\n",
    "# Show the result\n",
    "action_user_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1465f12-14d6-496c-88c6-306d19a79196",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----------+--------------------+\n|    action|bot_count|user_count|   bot_to_user_ratio|\n+----------+---------+----------+--------------------+\n|       new|       35|       590|0.059322033898305086|\n|       log|      825|       644|   1.281055900621118|\n|      edit|     9656|     11522|   0.838048949835098|\n|categorize|     5643|      8089|  0.6976140437631351|\n+----------+---------+----------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum as _sum, count as _count\n",
    "\n",
    "df = df.withColumn(\"bot\", col(\"bot\").cast(\"integer\"))\n",
    "# Group by 'action' and calculate bot and user counts\n",
    "action_df = df.groupBy(\"action\").agg(\n",
    "    _sum(\"bot\").alias(\"bot_count\"),\n",
    "    (_count(\"*\") - _sum(\"bot\")).alias(\"user_count\")\n",
    ")\n",
    "\n",
    "# Calculate the ratio of bots to users\n",
    "action_df = action_df.withColumn(\"bot_to_user_ratio\", col(\"bot_count\") / col(\"user_count\"))\n",
    "\n",
    "# Show the results\n",
    "action_df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b45d01b8-ec43-4230-b5a6-5d1dab01c500",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Kako se dobijeni podaci mogu koristiti na duze vremenske periode\n",
    "Ovde je simulirano deljenje velikog dataset na 2 manja 70-30 koji bi predstavljali koliki procenat poruka po kategoriji je napisao bot\n",
    "Ukoliko bi se ovaj procenat koji imamo od duzeg vremena vec naglo povecao na primer u poslednjem data set koji smo stavili da se testira\n",
    "To bi moglo znaciti da neko pokusava da napada nas sajt sa botovima iz raznih razloga (uklanjanje politickih materijala, propaganda i sl)\n",
    "<br>\n",
    "<br>\n",
    "u ovom primeru dozvoljeno je odstupanje od 5% od prethodne prosecne vrednosti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59cca127-b3cf-459e-a4c0-0da4353b74c3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------------+\n|    action|bot_activity_percent_train|\n+----------+--------------------------+\n|       new|       0.08823293494826343|\n|       log|        2.2379080773241355|\n|      edit|        27.063447501403704|\n|categorize|        15.966150637683485|\n+----------+--------------------------+\n\n+----------+-------------------------+\n|    action|bot_activity_percent_test|\n+----------+-------------------------+\n|       new|       0.1236564253781033|\n|       log|       2.4826405402834584|\n|      edit|       27.651479121088173|\n|categorize|       15.808998382954437|\n+----------+-------------------------+\n\n+----------+--------------------------+-------------------------+-------------------+\n|    action|bot_activity_percent_train|bot_activity_percent_test|        perc_change|\n+----------+--------------------------+-------------------------+-------------------+\n|       new|       0.08823293494826343|       0.1236564253781033| 40.147695926255786|\n|       log|        2.2379080773241355|       2.4826405402834584| 10.935769231949383|\n|      edit|        27.063447501403704|       27.651479121088173| 2.1727890345602447|\n|categorize|        15.966150637683485|       15.808998382954437|-0.9842839285139651|\n+----------+--------------------------+-------------------------+-------------------+\n\n+------+--------------------------+-------------------------+------------------+\n|action|bot_activity_percent_train|bot_activity_percent_test|       perc_change|\n+------+--------------------------+-------------------------+------------------+\n|   new|       0.08823293494826343|       0.1236564253781033|40.147695926255786|\n|   log|        2.2379080773241355|       2.4826405402834584|10.935769231949383|\n+------+--------------------------+-------------------------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count, when\n",
    "\n",
    "# Split the DataFrame into training and testing sets\n",
    "train_df, test_df = df.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Calculate total message counts for training and testing DataFrames\n",
    "total_train_msgs = train_df.count()\n",
    "total_test_msgs = test_df.count()\n",
    "\n",
    "# Aggregate data for training DataFrame with percentage calculation\n",
    "aggregated_train_df = train_df.groupBy(\"action\").agg(\n",
    "    (count(when(col(\"bot\") == True, True)) / total_train_msgs * 100).alias(\"bot_activity_percent_train\")\n",
    ")\n",
    "aggregated_train_df.show()\n",
    "\n",
    "# Aggregate data for testing DataFrame with percentage calculation\n",
    "aggregated_test_df = test_df.groupBy(\"action\").agg(\n",
    "    (count(when(col(\"bot\") == True, True)) / total_test_msgs * 100).alias(\"bot_activity_percent_test\")\n",
    ")\n",
    "aggregated_test_df.show()\n",
    "\n",
    "# Join the aggregated data on 'action'\n",
    "joined_df = aggregated_train_df.join(aggregated_test_df, \"action\")\n",
    "\n",
    "# Calculate the percentage change in bot activity\n",
    "joined_df = joined_df.withColumn(\"perc_change\", \n",
    "                                 (col(\"bot_activity_percent_test\") - col(\"bot_activity_percent_train\")) / col(\"bot_activity_percent_train\") * 100)\n",
    "\n",
    "joined_df.show()\n",
    "\n",
    "# Filter where the increase is 5% or more\n",
    "increased_df = joined_df.filter(col(\"perc_change\") >= 5)\n",
    "\n",
    "# Show or alert the user\n",
    "increased_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80ef0189-a0e3-4cbc-a3eb-d8a27083e8a1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Takodje je moguce proveriti i prosecnu duzinu poruke od strane botova naspram korisnika po oblasti\n",
    "\n",
    "ukoliko neka od poruka drasticno premasi prosek mozda nije lose da se flaguje da je moderator proveri ili u slucaju da duzina logova se drasticno promeni moze naznaciti da imamo problem sa jednim od nasih botova.\n",
    "\n",
    "takodje mozemo zakljuciti da botovi obicno pisu krace nove poruke dok korisnici obicno pisu duze nove poruke tako da i po duzini poruka mozemo nekoga flagovati da je potencijalni bot account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b484b640-f40c-44d1-b165-5d71c0f28840",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+------------------------+\n|    action|avg_len_bot_comments|avg_len_non_bot_comments|\n+----------+--------------------+------------------------+\n|       new|   36.42857142857143|       118.0442930153322|\n|       log|  101.81074481074481|      57.323232323232325|\n|      edit|  125.53744174003107|       74.23206167226725|\n|categorize|  125.81694134325713|       76.17999752750649|\n+----------+--------------------+------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import length, avg\n",
    "\n",
    "# Add a new column for comment length\n",
    "df_with_length = df.withColumn(\"comment_length\", length(df[\"comment\"]))\n",
    "\n",
    "# Calculate average comment length for bots\n",
    "bot_avg_comment_length = df_with_length.filter(df_with_length[\"bot\"] == True).groupBy(\"action\").agg(avg(\"comment_length\").alias(\"avg_len_bot_comments\"))\n",
    "\n",
    "# Calculate average comment length for non-bots\n",
    "non_bot_avg_comment_length = df_with_length.filter(df_with_length[\"bot\"] == False).groupBy(\"action\").agg(avg(\"comment_length\").alias(\"avg_len_non_bot_comments\"))\n",
    "\n",
    "# Join the two DataFrames on the action column\n",
    "comparison_df = bot_avg_comment_length.join(non_bot_avg_comment_length, \"action\")\n",
    "\n",
    "# Show the result\n",
    "comparison_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39975ff3-264d-49af-91ca-bfb579370355",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Najcesce koriscenje reci kod botova i kod korisnika\n",
    "mozemo i proveriti koje su najcesce koriscenje reci od strane botova naspram regularnih korisnika.\n",
    "potrebno je dodatno urediti dataset\n",
    "nazalost zbog limitacije databricks nije bilo moguce pokrenuti uklanjanje svih reci koje nisu imale preterano smisla da se nadju u listi kao na primer pocetak i kraj zavrsavanja komentara sto smo dobili sa api /* *i* */\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae18c985-ca48-4f94-95b9-a57de7be4f6c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 words used by bots:\n+---------------+-----+\n|           word|count|\n+---------------+-----+\n|               |18179|\n|             /*| 5763|\n|             */| 5754|\n|       category| 5509|\n|              -| 4244|\n|           page| 3649|\n|         within| 3643|\n|       included| 3643|\n|        pages]]| 3641|\n|        removed| 3421|\n|       {{wpbs}}| 3017|\n|      {{wpbs}}.| 2993|\n|         rating| 2258|\n|          added| 2159|\n|         adding| 2063|\n|              1| 1937|\n|geograph.org.uk| 1746|\n|  {{wikiproject| 1695|\n|          vital| 1637|\n|    articles]]:| 1637|\n+---------------+-----+\nonly showing top 20 rows\n\nTop 20 words used by regular users:\n+--------------------+-----+\n|                word|count|\n+--------------------+-----+\n|                    | 9666|\n|                  /*| 6833|\n|                  */| 6598|\n|            category| 6327|\n|               added| 5674|\n|             removed| 1383|\n|             tangkis| 1311|\n|                bulu| 1311|\n|wbsetdescription-...| 1311|\n|            turnamen| 1311|\n|                page| 1056|\n|                   -| 1013|\n|wbsetclaim-create...|  920|\n|             pages]]|  892|\n|              within|  870|\n|            included|  865|\n|                  de|  831|\n|wbcreateclaim-cre...|  808|\n|                2024|  709|\n|                  la|  707|\n+--------------------+-----+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode, col\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "df = df.filter(col(\"comment\").isNotNull() & (col(\"comment\").cast(\"string\") == col(\"comment\")))\n",
    "\n",
    "\n",
    "# # Remove '/*' and '*/'\n",
    "# df = df.withColumn(\"comment\", regexp_replace(\"comment\", \"\\\\/\\*\", \"\"))\n",
    "\n",
    "# # Remove numbers\n",
    "# df = df.withColumn(\"comment\", regexp_replace(\"comment\", \"\\\\d+\", \"\"))\n",
    "\n",
    "# Tokenize the comments\n",
    "tokenizer = Tokenizer(inputCol=\"comment\", outputCol=\"words\")\n",
    "df_words = tokenizer.transform(df)\n",
    "\n",
    "# Remove stopwords\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "df_filtered = remover.transform(df_words)\n",
    "\n",
    "# Explode the words into separate rows\n",
    "df_exploded = df_filtered.withColumn(\"word\", explode(col(\"filtered_words\")))\n",
    "\n",
    "# Filter for bots and non-bots, then count word frequencies\n",
    "bot_word_counts = df_exploded.filter(df_exploded[\"bot\"] == True).groupBy(\"word\").count().orderBy(\"count\", ascending=False)\n",
    "non_bot_word_counts = df_exploded.filter(df_exploded[\"bot\"] == False).groupBy(\"word\").count().orderBy(\"count\", ascending=False)\n",
    "\n",
    "# Show top 20 words for bots and non-bots\n",
    "print(\"Top 20 words used by bots:\")\n",
    "bot_word_counts.show(20)\n",
    "\n",
    "print(\"Top 20 words used by regular users:\")\n",
    "non_bot_word_counts.show(20)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Analiza 1 koliko botova mi radi sta po sajtu",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
